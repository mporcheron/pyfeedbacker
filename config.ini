[app]

; Name of the application
name = My Coursework

; Temporary directory where to save the submission while marking it
dir_temp = _temp

; Directory where submissions are stored. Each submission should be in a 
; directory of its own, where its name is passed as an argument to pyfeedbacker
; using the -m argument
dir_submissions = _submissions

; Enable debugging
; 
; At the moment, this basically is used to allow the application to crash
; ungracefully
debug = True


[scorer]

; Enable submission score statistics footer (default: False)
enable_footer = False


[marker]

; Enable submission mark statistics footer (default: True)
enable_footer = True

; Number of columnns for marks on mark distribution graph
graph_columns = 10


[model]

; Which model to use (currently only 'file' is supported)
type = file


[model_file]
; Directory to save the model data
directory = _output

; Filename for CSV of raw scores
file_scores = %(directory)s/scores.csv

; Filename for CSV of finalised marks
file_marks = %(directory)s/marks.csv

; Filename for JSON of raw feedback
file_feedbacks = %(directory)s/feedbacks.json

; Filename for finalised feedback (for the student). Use ##submission##
; for the submission ID
file_final_feedback = %(directory)s/feedback-##submission##.txt

; Filename for JSON of outcomes
file_outcomes = %(directory)s/outcomes.json

; Filename for JSON of marks for each outcome
file_outcomes_marks = %(directory)s/weights.json


[assessment]

; Initial number of marks
score_init = 0

; Minimum score possible
score_min = 0

; Maximum score possible
score_max = 100 

; Minimum mark possible
mark_min = %(score_min)s

; Maximum mark possible
mark_max = %(score_max)s

; List of stages of the submission as a comma-separated list
;
; For each stage, you must have a segment of configuration below with the
; name "stage_XXX" where XXX is the name of the stage
; 
; For example, if your list of stages is:
;   stages = init, execute, finalise
; you will need three ini segments, like so:
;   [stage_init]
;
;   ; Label for the stage
;   label = Initialise
;
;   ; Handler for the stage
;   ; Currently this is: HandlerNone          (does nothing)
;   ;                    HandlerQuestionnaire (user answers questions)
;   ;                    HandlerPython        (execute Python code)
;   ;                    HandlerProcess       (execute external process)
;   handler = HandlerExecution
;
stages = init, isgood, finalise

; Auto-progress on success (default: True)
progress_on_success = True

; Halt feedback generation if an error occurs (default: False)
halt_on_error = False

; Scores are marks (default: true, each score equals one mark)
; If False, you will have to do a post-hoc score-to-mark conversion
;   You may want to do this when you want to decide a weighting at the end
;   of marking.
;
; If True, scores are automatically applied to submission's mark.
scores_are_marks = False


[stage_init]

; Label for the stage
label = Initialise

; Handler for the stage
handler = HandlerPython

; Minimum number for the score (set to false to disable, default: false)
score_min = 0

; Maximum number for the score
score_max = 1

; Automatically preprend this feedback
feedback_pre = My coursework feedback - (##score##/##score_max##)

; Automatically append this feedback
feedback_post = 

; Halt feedback generation if an error occurs (default: false)
halt_on_error = true

; Copy the following folder into the temporary directory (default: '')
# framework_directory = _framework


[stage_isgood]

; Label for the stage
label = Is it good?

; Handler for the stage
handler = HandlerForm

; Maximum number for the score (set to false to disable)
; score_min = 0

; Maximum number for the score (set to false to disable)
; score_max = 20

; Automatically preprend this feedback
feedback_pre = 
  1. ASSESSMENT OF CODING QUALITY (##stage_isgood_score##/##stage_isgood_score_max##)\n

; Scales for answering questions as JSON arrays
scale_set1 = ["N/A", "No", "Yes"]
scale_set2 = ["Very Poor", "Poor", "OK", "Good", "Very Good"]
scale_set3 = ["N/A", "Very Poor", "Poor", "OK", "Good", "Very Good", "Excellent"]

; Questions, the scale used, the scale and score
question1   = How would you rate the coding style?
type1       = scale
answer1     = scale_set2
score1      = 0,2,4,6,6
feedback1   = 
  Your coding style was very poor, you should revisit the lecture material.
  Your coding style was poor, you should revisit the lecture material.
  Your coding style was OK but there was room for improvement, you should revisit the lecture material.
  Your coding style was very good, but try to always be consistently excellent in future.
  Your coding style was very good!
required1   = True

question2   = How would you rate variable naming?
type2       = scale
answer2     = scale_set2
score2      = 0,1,2,3,4
feedback2   = 
  Your variable names were not always that good, please remember that code should be self documenting through clear structures, syntax, and variable/function naming.
  Your variable names were not always that good, please remember that code should be self documenting through clear structures, syntax, and variable/function naming.
  Your variable names were OK but please remember that code should always be self documenting through clear structures, syntax, and variable/function naming.
  Your variable names were pretty good, pleased try to ensure that variable/function names are always self-documenting and clear.
  Your variable names were great and very clear to understand!
required2   = True

question3   = Did they complete the task to a good standard?
type3       = scale
answer3     = ["No", "Yes"]
score3      = 0,3
feedback3   = 
  \n\nOverall, you sadly didn't complete the task to a good standard, as expected.
  \n\nOverall, you completed the task to a good standard.
required3   = True

question4   = Did they complete bonus task to a good standard?
type4       = scale
answer4     = scale_set1
score4      = 0,2,3
feedback4   = 
  You didn't attempt the bonus task, so no marks were awarded here.
  The attempt at the bonus task was lacking somewhat.
  You did manage to achieve a few extra marks for completing the bonus task to a good standard.
required4   = True

question5   = Enter some bonus marks
type5       = input_score
min5        = 0
max5        = 4
required5   = False

question6   = Enter some extra feedback
type6       = input_feedback


[stage_finalise]

; Label for the stage
label = Finalise

; Handler for the stage
handler = HandlerEditText

; Selective feedback based on score
selective_0_24 = 
  2. SUMMARY
  Your score is rather low in this coursework, suggesting you need to revise the course material much more closely.

selective_25_49 = 
  2. SUMMARY
  Although you attempted some of this coursework, your overall mark is a little on the low side.

selective_50_69 =
  2. SUMMARY
  You did well in this coursework.

selective_70_84 = 
  2. SUMMARY
  You did very well in this coursework.

selective_85_94 = 
  2. SUMMARY
  You did exceptionally well in this coursework.

selective_95_100 = 
  2. SUMMARY
  Your coursework was close to faultless.